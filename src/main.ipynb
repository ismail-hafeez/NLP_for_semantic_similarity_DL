{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-11-10T17:02:10.018342Z",
          "iopub.status.busy": "2025-11-10T17:02:10.017916Z",
          "iopub.status.idle": "2025-11-10T17:02:10.024674Z",
          "shell.execute_reply": "2025-11-10T17:02:10.023921Z",
          "shell.execute_reply.started": "2025-11-10T17:02:10.018313Z"
        },
        "id": "NZBa-WQ67SNo",
        "outputId": "a7121121-46da-4157-e041-53a31a4a9691",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-10T17:02:10.026345Z",
          "iopub.status.busy": "2025-11-10T17:02:10.025985Z",
          "iopub.status.idle": "2025-11-10T17:02:16.011592Z",
          "shell.execute_reply": "2025-11-10T17:02:16.011045Z",
          "shell.execute_reply.started": "2025-11-10T17:02:10.026290Z"
        },
        "id": "XK7tBlsb7SNr",
        "outputId": "9b3929a6-759a-4254-b1f1-f654a5a5c4fb",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total clauses: 150881\n",
            "Unique clause types: 395\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clause_text</th>\n",
              "      <th>clause_type</th>\n",
              "      <th>source_file</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Certain Definitions. For purposes of this Agre...</td>\n",
              "      <td>certain-definitions</td>\n",
              "      <td>certain-definitions.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Certain Definitions. As used in this Agreement...</td>\n",
              "      <td>certain-definitions</td>\n",
              "      <td>certain-definitions.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Certain Definitions. For purposes of this Agre...</td>\n",
              "      <td>certain-definitions</td>\n",
              "      <td>certain-definitions.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Certain Definitions. For purposes of this Agre...</td>\n",
              "      <td>certain-definitions</td>\n",
              "      <td>certain-definitions.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Certain Definitions. As used in this Agreement...</td>\n",
              "      <td>certain-definitions</td>\n",
              "      <td>certain-definitions.csv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         clause_text          clause_type  \\\n",
              "0  Certain Definitions. For purposes of this Agre...  certain-definitions   \n",
              "1  Certain Definitions. As used in this Agreement...  certain-definitions   \n",
              "2  Certain Definitions. For purposes of this Agre...  certain-definitions   \n",
              "3  Certain Definitions. For purposes of this Agre...  certain-definitions   \n",
              "4  Certain Definitions. As used in this Agreement...  certain-definitions   \n",
              "\n",
              "               source_file  \n",
              "0  certain-definitions.csv  \n",
              "1  certain-definitions.csv  \n",
              "2  certain-definitions.csv  \n",
              "3  certain-definitions.csv  \n",
              "4  certain-definitions.csv  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PATH = '../data'\n",
        "\n",
        "# Read all CSV files and combine\n",
        "all_data = []\n",
        "for file in os.listdir(PATH):\n",
        "    if file.endswith(\".csv\"):\n",
        "        df = pd.read_csv(os.path.join(PATH, file))\n",
        "        df[\"source_file\"] = file\n",
        "        all_data.append(df)\n",
        "\n",
        "data = pd.concat(all_data, ignore_index=True)\n",
        "print(\"Total clauses:\", len(data))\n",
        "print(\"Unique clause types:\", data[\"clause_type\"].nunique())\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_shape():\n",
        "    for file in os.listdir(PATH):\n",
        "        if file.endswith(\".csv\"):\n",
        "            csv_file = os.path.join(PATH, file)\n",
        "            df = pd.read_csv(csv_file)\n",
        "            print(f\"{csv_file} | Shape: {df.shape}\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-10T17:02:16.012554Z",
          "iopub.status.busy": "2025-11-10T17:02:16.012337Z",
          "iopub.status.idle": "2025-11-10T17:02:17.660758Z",
          "shell.execute_reply": "2025-11-10T17:02:17.659987Z",
          "shell.execute_reply.started": "2025-11-10T17:02:16.012538Z"
        },
        "id": "vFXaEqKI7SNr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def clean_text(t):\n",
        "    t = str(t).strip().lower()\n",
        "    t = \" \".join(t.split())\n",
        "    return t\n",
        "\n",
        "data[\"clause_text\"] = data[\"clause_text\"].apply(clean_text)\n",
        "data = data.dropna(subset=[\"clause_text\", \"clause_type\"]).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Build Pair Dataset (positive & negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-10T17:02:17.662903Z",
          "iopub.status.busy": "2025-11-10T17:02:17.662537Z",
          "iopub.status.idle": "2025-11-10T17:02:18.136602Z",
          "shell.execute_reply": "2025-11-10T17:02:18.135982Z",
          "shell.execute_reply.started": "2025-11-10T17:02:17.662880Z"
        },
        "id": "29Nhnnqa7SNr",
        "outputId": "58d1b226-750d-4a94-ab61-f0e9bcbdf9d5",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total pairs: 301350\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text1</th>\n",
              "      <th>text2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>absence of certain changes. there have been no...</td>\n",
              "      <td>absence of certain changes. except as disclose...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>absence of certain changes. there have been no...</td>\n",
              "      <td>compensation and benefits. for all services re...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>absence of certain changes. since september 30...</td>\n",
              "      <td>absence of certain changes. as of the closing ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>absence of certain changes. since september 30...</td>\n",
              "      <td>erisa. borrower shall, and shall cause each of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>absence of certain changes. since december 31,...</td>\n",
              "      <td>absence of certain changes. except as disclose...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               text1  \\\n",
              "0  absence of certain changes. there have been no...   \n",
              "1  absence of certain changes. there have been no...   \n",
              "2  absence of certain changes. since september 30...   \n",
              "3  absence of certain changes. since september 30...   \n",
              "4  absence of certain changes. since december 31,...   \n",
              "\n",
              "                                               text2  label  \n",
              "0  absence of certain changes. except as disclose...      1  \n",
              "1  compensation and benefits. for all services re...      0  \n",
              "2  absence of certain changes. as of the closing ...      1  \n",
              "3  erisa. borrower shall, and shall cause each of...      0  \n",
              "4  absence of certain changes. except as disclose...      1  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def make_pairs(df, num_pos=1, num_neg=1, seed=42):\n",
        "    random.seed(seed)\n",
        "    pairs = []\n",
        "    labels = []\n",
        "    grouped = df.groupby(\"clause_type\")[\"clause_text\"].apply(list).to_dict()\n",
        "    types = list(grouped.keys())\n",
        "\n",
        "    for t in types:\n",
        "        examples = grouped[t]\n",
        "        for ex in examples:\n",
        "            # Positive pairs\n",
        "            for _ in range(num_pos):\n",
        "                pos = random.choice(examples)\n",
        "                if pos != ex:\n",
        "                    pairs.append((ex, pos))\n",
        "                    labels.append(1)\n",
        "            # Negative pairs\n",
        "            for _ in range(num_neg):\n",
        "                neg_type = random.choice(types)\n",
        "                while neg_type == t:\n",
        "                    neg_type = random.choice(types)\n",
        "                neg = random.choice(grouped[neg_type])\n",
        "                pairs.append((ex, neg))\n",
        "                labels.append(0)\n",
        "\n",
        "    pair_df = pd.DataFrame({\"text1\": [p[0] for p in pairs],\n",
        "                            \"text2\": [p[1] for p in pairs],\n",
        "                            \"label\": labels})\n",
        "    return pair_df\n",
        "\n",
        "pair_df = make_pairs(data, num_pos=1, num_neg=1)\n",
        "print(\"Total pairs:\", len(pair_df))\n",
        "pair_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tokenization and Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-10T17:02:18.137627Z",
          "iopub.status.busy": "2025-11-10T17:02:18.137343Z",
          "iopub.status.idle": "2025-11-10T17:02:24.188331Z",
          "shell.execute_reply": "2025-11-10T17:02:24.187705Z",
          "shell.execute_reply.started": "2025-11-10T17:02:18.137597Z"
        },
        "id": "0Gkh4FTw7SNr",
        "outputId": "2486366c-5e86-4598-8c81-f3f65338f63b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Building vocab: 100%|██████████| 150881/150881 [00:06<00:00, 25007.26it/s]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
        "\n",
        "# Build vocab\n",
        "token_counts = Counter()\n",
        "for t in tqdm(data[\"clause_text\"], desc=\"Building vocab\"):\n",
        "    token_counts.update(tokenize(t))\n",
        "\n",
        "min_freq = 3\n",
        "vocab = [\"<pad>\", \"<unk>\"] + [w for w, c in token_counts.items() if c >= min_freq]\n",
        "stoi = {w: i for i, w in enumerate(vocab)}\n",
        "itos = {i: w for w, i in stoi.items()}\n",
        "\n",
        "def encode(text, max_len=100):\n",
        "    tokens = tokenize(text)\n",
        "    ids = [stoi.get(t, 1) for t in tokens[:max_len]]  # 1 = <unk>\n",
        "    if len(ids) < max_len:\n",
        "        ids += [0] * (max_len - len(ids))\n",
        "    return ids, len(tokens[:max_len])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-10T17:02:24.189426Z",
          "iopub.status.busy": "2025-11-10T17:02:24.189113Z",
          "iopub.status.idle": "2025-11-10T17:02:24.348025Z",
          "shell.execute_reply": "2025-11-10T17:02:24.347170Z",
          "shell.execute_reply.started": "2025-11-10T17:02:24.189406Z"
        },
        "id": "-ZbeE5dv7SNs",
        "outputId": "1ffb5217-0a05-4881-85cd-650b5195b51b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 241080 Val: 30135 Test: 30135\n"
          ]
        }
      ],
      "source": [
        "class ClausePairDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        x1, l1 = encode(row.text1)\n",
        "        x2, l2 = encode(row.text2)\n",
        "        y = row.label\n",
        "        return torch.tensor(x1), torch.tensor(l1), torch.tensor(x2), torch.tensor(l2), torch.tensor(y)\n",
        "\n",
        "# Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(pair_df, test_size=0.2, random_state=42, stratify=pair_df[\"label\"])\n",
        "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42, stratify=test_df[\"label\"])\n",
        "\n",
        "train_ds = ClausePairDataset(train_df)\n",
        "val_ds = ClausePairDataset(val_df)\n",
        "test_ds = ClausePairDataset(test_df)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64)\n",
        "test_loader = DataLoader(test_ds, batch_size=64)\n",
        "\n",
        "print(\"Train:\", len(train_ds), \"Val:\", len(val_ds), \"Test:\", len(test_ds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Siamese BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-10T17:02:24.349137Z",
          "iopub.status.busy": "2025-11-10T17:02:24.348863Z",
          "iopub.status.idle": "2025-11-10T17:02:24.707570Z",
          "shell.execute_reply": "2025-11-10T17:02:24.706991Z",
          "shell.execute_reply.started": "2025-11-10T17:02:24.349109Z"
        },
        "id": "suamGiQj7SNs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class BiLSTMEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=200, hidden=256, num_layers=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden, num_layers=num_layers,\n",
        "                            bidirectional=True, batch_first=True,\n",
        "                            dropout=dropout if num_layers > 1 else 0)\n",
        "        self.hidden_dim = hidden * 2\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        emb = self.emb(x)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        packed_out, (hn, cn) = self.lstm(packed)\n",
        "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
        "        mask = (x != 0).float().unsqueeze(-1)\n",
        "        summed = (out * mask).sum(1)\n",
        "        rep = summed / lengths.unsqueeze(1)\n",
        "        return rep\n",
        "\n",
        "class SiameseSim(nn.Module):\n",
        "    def __init__(self, encoder, hidden_mlp=256):\n",
        "        super().__init__()\n",
        "        self.enc = encoder\n",
        "        D = self.enc.hidden_dim\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(D * 4, hidden_mlp),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_mlp, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, len1, x2, len2):\n",
        "        u = self.enc(x1, len1)\n",
        "        v = self.enc(x2, len2)\n",
        "        feats = torch.cat([u, v, torch.abs(u - v), u * v], dim=1)\n",
        "        logits = self.mlp(feats).squeeze(1)\n",
        "        return logits\n",
        "\n",
        "encoder = BiLSTMEncoder(vocab_size=len(vocab))\n",
        "model1 = SiameseSim(encoder).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-10T17:02:24.708558Z",
          "iopub.status.busy": "2025-11-10T17:02:24.708305Z",
          "iopub.status.idle": "2025-11-10T17:02:24.715229Z",
          "shell.execute_reply": "2025-11-10T17:02:24.714550Z",
          "shell.execute_reply.started": "2025-11-10T17:02:24.708535Z"
        },
        "id": "_Q4rm-Mj7SNs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=5, lr=1e-3):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "\n",
        "    best_f1 = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x1, l1, x2, l2, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            x1, l1, x2, l2, y = x1.to(device), l1.to(device), x2.to(device), l2.to(device), y.float().to(device)\n",
        "            logits = model(x1, l1, x2, l2)\n",
        "            loss = criterion(logits, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        val_f1, val_acc = evaluate(model, val_loader)\n",
        "        print(f\"Epoch {epoch+1}: loss={total_loss/len(train_loader):.4f}, val_f1={val_f1:.4f}, val_acc={val_acc:.4f}\")\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            torch.save(model.state_dict(), \"best_model.pt\")\n",
        "    print(\"Best Val F1:\", best_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-10T18:20:57.580499Z",
          "iopub.status.busy": "2025-11-10T18:20:57.579736Z",
          "iopub.status.idle": "2025-11-10T18:20:57.588141Z",
          "shell.execute_reply": "2025-11-10T18:20:57.587381Z",
          "shell.execute_reply.started": "2025-11-10T18:20:57.580475Z"
        },
        "id": "w0BssKwn7SNs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    roc_auc_score, average_precision_score, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "def evaluate(model, loader, verbose=True):\n",
        "    \"\"\"\n",
        "    Evaluate a similarity model on a given DataLoader.\n",
        "\n",
        "    Returns:\n",
        "        dict with accuracy, precision, recall, f1, roc_auc, pr_auc\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    y_true, y_pred, y_prob = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x1, l1, x2, l2, y in loader:\n",
        "            x1, l1, x2, l2 = x1.to(device), l1.to(device), x2.to(device), l2.to(device)\n",
        "            logits = model(x1, l1, x2, l2)\n",
        "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            y_true.extend(y.numpy())\n",
        "            y_pred.extend(preds)\n",
        "            y_prob.extend(probs)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_prob = np.array(y_prob)\n",
        "\n",
        "    # ---- Core Metrics ----\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
        "    roc_auc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else 0.0\n",
        "    pr_auc = average_precision_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else 0.0\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n===== Evaluation Metrics =====\")\n",
        "        print(f\"Accuracy  (Overall correctness):       {acc:.4f}\")\n",
        "        print(f\"Precision (Exactness):                 {prec:.4f}\")\n",
        "        print(f\"Recall    (Completeness):              {rec:.4f}\")\n",
        "        print(f\"F1-Score  (Balance of P/R):            {f1:.4f}\")\n",
        "        print(f\"ROC-AUC   (Ranking ability):           {roc_auc:.4f}\")\n",
        "        print(f\"PR-AUC    (Precision-Recall curve):    {pr_auc:.4f}\")\n",
        "        print(\"=====================================\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-10T17:02:24.733671Z",
          "iopub.status.busy": "2025-11-10T17:02:24.733428Z",
          "iopub.status.idle": "2025-11-10T17:46:02.709298Z",
          "shell.execute_reply": "2025-11-10T17:46:02.708188Z",
          "shell.execute_reply.started": "2025-11-10T17:02:24.733653Z"
        },
        "id": "7pvkNKsf7SNt",
        "outputId": "0414291b-0a7f-44a6-8a95-aebb0c24dd78",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/15: 100%|██████████| 3767/3767 [04:09<00:00, 15.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: loss=0.0042, val_f1=0.9995, val_acc=0.9995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/15: 100%|██████████| 3767/3767 [04:09<00:00, 15.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: loss=0.0033, val_f1=0.9990, val_acc=0.9990\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/15: 100%|██████████| 3767/3767 [04:09<00:00, 15.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: loss=0.0028, val_f1=0.9996, val_acc=0.9996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/15: 100%|██████████| 3767/3767 [04:10<00:00, 15.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: loss=0.0024, val_f1=0.9995, val_acc=0.9995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/15: 100%|██████████| 3767/3767 [04:09<00:00, 15.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: loss=0.0027, val_f1=0.9995, val_acc=0.9995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/15: 100%|██████████| 3767/3767 [04:09<00:00, 15.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: loss=0.0022, val_f1=0.9995, val_acc=0.9995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/15: 100%|██████████| 3767/3767 [04:10<00:00, 15.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: loss=0.0023, val_f1=0.9992, val_acc=0.9992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/15: 100%|██████████| 3767/3767 [04:09<00:00, 15.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: loss=0.0022, val_f1=0.9996, val_acc=0.9996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/15: 100%|██████████| 3767/3767 [04:08<00:00, 15.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: loss=0.0022, val_f1=0.9995, val_acc=0.9995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/15:   1%|          | 20/3767 [00:01<04:20, 14.41it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_48/1530730116.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_48/2202562391.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, epochs, lr)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_48/4201275905.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_model(model1, train_loader, val_loader, epochs=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2: BiLSTM + Self-Attention Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "execution_failed": "2025-11-10T18:29:51.174Z",
          "iopub.execute_input": "2025-11-10T17:46:12.688135Z",
          "iopub.status.busy": "2025-11-10T17:46:12.687411Z"
        },
        "id": "QhtsyN6G7SNt",
        "outputId": "1cd7c797-278d-4d4e-95b2-eecec52bb688",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5: 100%|██████████| 3767/3767 [04:13<00:00, 14.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss=0.0254, val_f1=0.9991, val_acc=0.9991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5: 100%|██████████| 3767/3767 [04:14<00:00, 14.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: loss=0.0037, val_f1=0.9991, val_acc=0.9991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5: 100%|██████████| 3767/3767 [04:14<00:00, 14.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: loss=0.0022, val_f1=0.9995, val_acc=0.9995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/5: 100%|██████████| 3767/3767 [04:14<00:00, 14.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: loss=0.0017, val_f1=0.9995, val_acc=0.9995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/5: 100%|██████████| 3767/3767 [04:13<00:00, 14.85it/s]\n"
          ]
        }
      ],
      "source": [
        "class AttentionPool(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.w = nn.Linear(hidden_dim, 1)\n",
        "    def forward(self, mem, mask):\n",
        "        scores = self.w(mem).squeeze(-1)\n",
        "        scores = scores.masked_fill(~mask, -1e9)\n",
        "        attn = torch.softmax(scores, dim=1).unsqueeze(-1)\n",
        "        rep = (mem * attn).sum(1)\n",
        "        return rep\n",
        "\n",
        "class BiLSTMAttentionEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=200, hidden=256, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden, bidirectional=True, batch_first=True)\n",
        "        self.attn = AttentionPool(hidden * 2)\n",
        "        self.hidden_dim = hidden * 2\n",
        "    def forward(self, x, lengths):\n",
        "        emb = self.emb(x)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        packed_out, _ = self.lstm(packed)\n",
        "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
        "        mask = (x != 0)\n",
        "        rep = self.attn(out, mask)\n",
        "        return rep\n",
        "\n",
        "encoder2 = BiLSTMAttentionEncoder(vocab_size=len(vocab))\n",
        "model2 = SiameseSim(encoder2).to(device)\n",
        "\n",
        "train_model(model2, train_loader, val_loader, epochs=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-10T18:21:01.696462Z",
          "iopub.status.busy": "2025-11-10T18:21:01.695908Z",
          "iopub.status.idle": "2025-11-10T18:21:26.330075Z",
          "shell.execute_reply": "2025-11-10T18:21:26.329420Z",
          "shell.execute_reply.started": "2025-11-10T18:21:01.696442Z"
        },
        "id": "HgeQGFbm7SNt",
        "outputId": "f363f341-d9ac-448e-8af6-71d88011b153",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Evaluation Metrics =====\n",
            "Accuracy  (Overall correctness):       0.9997\n",
            "Precision (Exactness):                 0.9996\n",
            "Recall    (Completeness):              0.9999\n",
            "F1-Score  (Balance of P/R):            0.9997\n",
            "ROC-AUC   (Ranking ability):           0.9999\n",
            "PR-AUC    (Precision-Recall curve):    0.9998\n",
            "=====================================\n",
            "\n",
            "===== Evaluation Metrics =====\n",
            "Accuracy  (Overall correctness):       0.9992\n",
            "Precision (Exactness):                 0.9985\n",
            "Recall    (Completeness):              0.9999\n",
            "F1-Score  (Balance of P/R):            0.9992\n",
            "ROC-AUC   (Ranking ability):           0.9998\n",
            "PR-AUC    (Precision-Recall curve):    0.9995\n",
            "=====================================\n",
            "\n",
            "===== Final Comparison =====\n",
            "Siamese BiLSTM     — {'accuracy': 0.9997345279575245, 'precision': 0.9996013553916683, 'recall': 0.9998670831394962, 'f1': 0.9997342016080802, 'roc_auc': 0.9999338675191012, 'pr_auc': 0.9997977179639045}\n",
            "BiLSTM + Attention — {'accuracy': 0.999170399867264, 'precision': 0.9984735864082824, 'recall': 0.9998670831394962, 'f1': 0.999169848912502, 'roc_auc': 0.9997953016039316, 'pr_auc': 0.9994784411810144}\n"
          ]
        }
      ],
      "source": [
        "m1 = evaluate(model1 , test_loader)\n",
        "m2 = evaluate(model2 , test_loader)\n",
        "\n",
        "print(\"\\n===== Final Comparison =====\")\n",
        "print(f\"Siamese BiLSTM     — {m1}\")\n",
        "print(f\"BiLSTM + Attention — {m2}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 1698908,
          "sourceId": 2782728,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31193,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
